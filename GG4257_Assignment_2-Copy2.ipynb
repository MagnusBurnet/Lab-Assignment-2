{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b49045a4-20fd-45d0-bf40-9ebddac2883f",
   "metadata": {},
   "source": [
    "# **Lab 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15074b00-eb79-4970-b7c0-b7c2db852f71",
   "metadata": {},
   "source": [
    "## Challenge 1: Geodemographic Classification\n",
    "\n",
    "In this challenge I will create Geodemographic Classification using the k-means clustering Algorithm for the **City of Edinburgh**.\n",
    "\n",
    "The focus of the the classification is to inform **healthcare provision** decision making in Edinburgh.\n",
    "\n",
    "It will use demographic, health, economic and housing data from the [2011 census.](https://www.scotlandscensus.gov.uk/search-the-census#/topics)\n",
    "\n",
    "The following Topics and variables will be used to inform the classificiations:\n",
    "\n",
    "* **KS102SC** - Age structure - Demographics\n",
    "* >0 to 5\n",
    "* >30 to 44\n",
    "* >65 to 74\n",
    "* **QS104SC** - Sex - Demographics\n",
    "* >Females\n",
    "* >Males\n",
    "* **QS302SC** - General Health - Health\n",
    "* >Good health\n",
    "* >Bad health\n",
    "* **QS304SC** - Long Term Health Conditions\n",
    "* >No condition\n",
    "* >Pysical Disability\n",
    "* >Mental Health Condition\n",
    "* **QS301SCb** - Provision of unpaid care\n",
    "* >Provides no unpaid care\n",
    "* >Provides 35 to 49 hours unpaid care a week\n",
    "* **QS613SC** - Appoximated social grade\n",
    "* > AB Higher and intermediate managerial/administrative/professional\n",
    "* > C2 Skilled manual workers\n",
    "* > DE Semi-skilled and unskilled manual workers; on state benefit, unemployed, lowest grade workers',\n",
    "* **KS601SC** - Economic activity - Economic\n",
    "* >Economically active: Unemployed\n",
    "* >Economically active: Employee: Full-time\n",
    "* >Economically active: Full-time student\n",
    "* >Economically inactive: Retired\n",
    "* **KS601SCb** - Adults not in employment and dependent children\n",
    "* >No adults in employment in household: With dependent children\n",
    "* >Dependent children in household: All ages\n",
    "* **KS402SC** - Household Tenure\n",
    "* >Owned: Owned outright\n",
    "* >Rented: Council (Local Authorities)\n",
    "* >Rented: Private landlord or letting agency\n",
    "\n",
    "This selection topics is well suited to understanding the range of health needs and population characteristics in Edinburgh, informing health provision decision making.\n",
    "\n",
    "**Age and Sex:** These are cricual variables that influence heath risks as some conditions are more prevelant in certain age groups and sexes.\n",
    "\n",
    "**General health and long-term conditions:** These provide a direct indicator of a populations health. Identifying the presence of long term health conditions and disabilities is crucial to identifying groups with higher healthcare needs.\n",
    "\n",
    "**Unpaid care:** Unpaid caregivers often require unique healthcare provisions such as additional support, training and financial aid.\n",
    "\n",
    "**Economic Activity:** Economic activity and employment are directly linked to health, as they influence stress, poorer health and economic barriers to healthcare.\n",
    "\n",
    "**Language proficiency:** Language proficiency is a key determinant of access to healthcare. Non-English speakers may face barriers in accessing health information and communicating with healthcare providers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8839f3-f2ac-486a-9429-e87abbb6d823",
   "metadata": {},
   "source": [
    "### Preparing data from Census\n",
    "A range of datasets were downloaded from the 2011 Census database. These required some preprocessing. This was done in Microsoft Excel. These preprocessed files are availiable in the datafile.\n",
    "\n",
    "**Step 1:** Merge the seperate CSV files into 1 file and link to edinburgh output areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc0266-1c10-4323-9934-360acb35fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#Link to census data file\n",
    "csv_directory = \"Data_2/Census_Data\"\n",
    "\n",
    "# List all the CSV files in the Census_Data folder\n",
    "csv_files = [file for file in os.listdir(csv_directory) if file.endswith(\".csv\")]\n",
    "\n",
    "# Create empty DataFrame to store the merged data\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file\n",
    "for csv_file in csv_files:\n",
    "    csv_path = os.path.join(csv_directory, csv_file) \n",
    "    df_csv = pd.read_csv(csv_path, low_memory=False) \n",
    "    merged_data = pd.concat([merged_data, df_csv], axis=1)\n",
    "\n",
    "# Save the merged dataset as Merged_Census_Data.csv\n",
    "#merged_data.to_csv(\"Data_2/Merged_Census_Data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3663c65-3f60-41eb-8b6a-db3828ce4524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "#Link to edinburgh output areas\n",
    "shp_path = \"Data_2/Edinburgh_OA/scotland_oa_2011.shp\"\n",
    "gdf = gpd.read_file(shp_path)\n",
    "\n",
    "#Link to merged CSV file\n",
    "csv_path = \"Data_2/Merged_Census_Data.csv\"\n",
    "csv_data = pd.read_csv(csv_path, low_memory=False)\n",
    "\n",
    "# Merge the GeoDataFrame with the DataFrame based on the oa_code\n",
    "merged_data = gdf.merge(csv_data, left_on='code', right_on='oa_code', how='left')\n",
    "\n",
    "#Save data to shapefile\n",
    "#merged_data.to_file('Data_2/Merged_Shape/merged_data.shp', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaec906-ea57-44d4-ab80-122aceb03586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "attributes_to_plot = ['0 to 5',\n",
    "                      'No adults in employment in household: With dependent children',\n",
    "                      'Provides 1 to 19 hours unpaid care a week',\n",
    "                      'Economically active: Unemployed',\n",
    "                      '60 to 64',\n",
    "                      'Physical disability']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, attribute in enumerate(attributes_to_plot, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.histplot(merged_data[attribute].astype(str), kde=True)\n",
    "    plt.title(attribute)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd3c89-546f-4982-aacc-d496745b30be",
   "metadata": {},
   "source": [
    "### Standardization of areas\n",
    "\n",
    "As the output areas have different numbers of people and households, this next section is important to ensure that the values are starndardised in order that they are comparable.\n",
    "\n",
    "To do this, each variable is converted to a percentage of its areas total. This is done by defining each variables total and value column. A percentage is then calculated from these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0a95d-640b-42dd-b97e-a693153779cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(merged_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af86e0-924d-4273-b521-d81b06d85629",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This creates a function that creates a new dataframe \n",
    "def calculate_percentages(dataframe, total_columns, value_columns):\n",
    "\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    for total_col, value_col in zip(total_columns, value_columns):\n",
    "        percentage_col_name = f\"{value_col}_percentage\"\n",
    "\n",
    "        if total_col not in dataframe.columns:\n",
    "            raise ValueError(f\"Total column '{total_col}' not found in the DataFrame.\")\n",
    "        #convert value and total collums to numerics and create NaNs for missing data\n",
    "        dataframe[value_col] = pd.to_numeric(dataframe[value_col], errors='coerce')\n",
    "        dataframe[total_col] = pd.to_numeric(dataframe[total_col], errors='coerce')\n",
    "        \n",
    "        #Create a percentage from the value column and the total columns\n",
    "        result_df[percentage_col_name] = (dataframe[value_col] / dataframe[total_col]) * 100\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# List the total columns.\n",
    "total_cols = ['All people',\n",
    "              'All people',\n",
    "              'All people',\n",
    "              'All households',\n",
    "              'All people.1',\n",
    "              'All people.1',\n",
    "              'All people aged 16 to 74',\n",
    "              'All people aged 16 to 74',\n",
    "              'All people aged 16 to 74',\n",
    "              'All people aged 16 to 74',\n",
    "              'All people.2',\n",
    "              'All people.2',\n",
    "              'All people.2',\n",
    "              'All people.3', \n",
    "              'All people.3',\n",
    "              'All people aged 16 to 64 in households',\n",
    "              'All people aged 16 to 64 in households',\n",
    "              'All people aged 16 to 64 in households',\n",
    "              'All people.4',\n",
    "              'All people.4',\n",
    "              'All households.1',\n",
    "              'All households.1',\n",
    "              'All households.1',\n",
    "              ]\n",
    "# List the corresponding value columns. \n",
    "value_cols = [\n",
    "     '0 to 5',\n",
    "     '30 to 44',\n",
    "     '65 to 74',\n",
    "     'Dependent children in household: All ages',\n",
    "     'Males',\n",
    "     'Females',\n",
    "     'Economically active: Employee: Full-time',\n",
    "     'Economically active: Unemployed',\n",
    "     'Economically active: Full-time student',\n",
    "     'Economically inactive: Retired',\n",
    "     'No condition',\n",
    "     'Physical disability',\n",
    "     'Mental health condition',\n",
    "     'Provides no unpaid care',\n",
    "     'Provides 35 to 49 hours unpaid care a week',\n",
    "     'AB Higher and intermediate managerial/administrative/professional',\n",
    "     'C2 Skilled manual workers',\n",
    "     'DE Semi-skilled and unskilled manual workers; on state benefit, unemployed, lowest grade workers',\n",
    "     'Good health',\n",
    "     'Bad health',\n",
    "     'Owned: Owned outright',\n",
    "     'Rented: Council (Local authority)',\n",
    "     'Rented: Private landlord or letting agency',\n",
    "             ]\n",
    "\n",
    "#run the function using the value and total columns\n",
    "result_dataframe = calculate_percentages(merged_data, total_cols, value_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0763dc-7434-480b-b0d2-460b5478a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the new results dataframe with the merged data\n",
    "concatenated_df = pd.concat([merged_data, result_dataframe], axis=1, ignore_index=False)\n",
    "concatenated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18baa7b9-f9ad-4d05-b2b5-4599a704f2c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(concatenated_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31309fdf-0674-4ebe-8c9b-f34531db5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the columns needed for the future analysis\n",
    "#This list keeps the standardized data and geometry information and removes the rest\n",
    "keep_cols= [\n",
    "    'code',\n",
    "    'popcount',\n",
    "    'hhcount',\n",
    "    'geometry',\n",
    "     '0 to 5_percentage',\n",
    " '30 to 44_percentage',\n",
    " '65 to 74_percentage',\n",
    " 'Dependent children in household: All ages_percentage',\n",
    " 'Males_percentage',\n",
    " 'Females_percentage',\n",
    " 'Economically active: Employee: Full-time_percentage',\n",
    " 'Economically active: Unemployed_percentage',\n",
    " 'Economically active: Full-time student_percentage',\n",
    " 'Economically inactive: Retired_percentage',\n",
    " 'No condition_percentage',\n",
    " 'Physical disability_percentage',\n",
    " 'Mental health condition_percentage',\n",
    " 'Provides no unpaid care_percentage',\n",
    " 'Provides 35 to 49 hours unpaid care a week_percentage',\n",
    " 'AB Higher and intermediate managerial/administrative/professional_percentage',\n",
    " 'C2 Skilled manual workers_percentage',\n",
    " 'DE Semi-skilled and unskilled manual workers; on state benefit, unemployed, lowest grade workers_percentage',\n",
    " 'Good health_percentage',\n",
    " 'Bad health_percentage',\n",
    " 'Owned: Owned outright_percentage',\n",
    " 'Rented: Council (Local authority)_percentage',\n",
    " 'Rented: Private landlord or letting agency_percentage'\n",
    "\n",
    "]\n",
    "\n",
    "#create new dataframe with only the necessary columns\n",
    "edinburgh_census_data = concatenated_df[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7298e3f3-df24-4a83-a343-df96e9b78eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more easy manipulation we define short column names\n",
    "short_column_names = {\n",
    " '0 to 5_percentage': '0to5',\n",
    " '30 to 44_percentage': '30to44',\n",
    " '65 to 74_percentage': '65to74',\n",
    " 'Dependent children in household: All ages_percentage':'Dep_child',\n",
    " 'Males_percentage':'Men',\n",
    " 'Females_percentage':'Women',\n",
    " 'Economically active: Employee: Full-time_percentage':'Employed',\n",
    " 'Economically active: Unemployed_percentage':'Unemployed',\n",
    " 'Economically active: Full-time student_percentage':'Student',\n",
    " 'Economically inactive: Retired_percentage':'Retired',\n",
    " 'No condition_percentage':'No_Condition',\n",
    " 'Physical disability_percentage':'Phys_Disability',\n",
    " 'Mental health condition_percentage':'Ment_Condition',\n",
    " 'Provides no unpaid care_percentage':'No_unpaid_care',\n",
    " 'Provides 35 to 49 hours unpaid care a week_percentage':'Unpaid_care',\n",
    " 'AB Higher and intermediate managerial/administrative/professional_percentage':'Professional',\n",
    " 'C2 Skilled manual workers_percentage':'Skilled',\n",
    " 'DE Semi-skilled and unskilled manual workers; on state benefit, unemployed, lowest grade workers_percentage':'Unskilled',\n",
    " 'Good health_percentage':'Healthy',\n",
    " 'Bad health_percentage':'Unhealthy',\n",
    " 'Owned: Owned outright_percentage':'House_owned',\n",
    " 'Rented: Council (Local authority)_percentage':'Council_house',\n",
    " 'Rented: Private landlord or letting agency_percentage':'House_rented'\n",
    "\n",
    "}\n",
    "\n",
    "edinburgh_census_data = edinburgh_census_data.rename(columns=short_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f0c15a-105e-40ca-b317-78fa517174aa",
   "metadata": {},
   "source": [
    "### Measure the variables for association\n",
    "\n",
    "Measuring each variables correlation with the others is important as if two variables are highly correlated then a certain phenomenon may be given a higher weight as they are being represented by two or more variables.\n",
    "\n",
    "In this section every variable is tested for its correlation with every other vairable using a Pearsons coefficient. If two variables are highly correlated (>0.8) then one of the variables is removed in order to avoid multi multicollinearity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b1dfab-ac10-4088-b23e-b109ee077037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the data to include only numeric values\n",
    "numeric_columns = edinburgh_census_data.select_dtypes(include='float64')\n",
    "z_score_df = (numeric_columns - numeric_columns.mean()) / numeric_columns.std(ddof=0)\n",
    "z_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa18269-effd-436c-85e4-695b0377b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caluclate and plot the z values for each relationship\n",
    "corr = z_score_df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee990d-2a42-4452-a65b-625c0ce34234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For ease of interpretation,\n",
    "#the following code plots the same table however highlights only the variables with >0.75 correlation.\n",
    "threshold = 0.75 \n",
    "\n",
    "highly_correlated = (corr.abs() > threshold) & (corr.abs() < 1.0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(highly_correlated, cmap='coolwarm', cbar=False, annot=True)\n",
    "\n",
    "plt.title('Highly Correlated Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d11cf3-19bd-40c2-942e-07601cbd64c3",
   "metadata": {},
   "source": [
    "As you can see, there are a few variables which are highly correlated; **No_Condition**, and **Phys_Disability**. This makes sense as if a household were to have a family member with a physical disability, they will not be listed as being a no condition household\n",
    "\n",
    "There is also a correlation between **Retired** and **65to74**. This is also understandable as the retirement age in the UK is 65.\n",
    "\n",
    "**Men** and **Women** are also highly correlated.\n",
    "\n",
    "One of each of these variables will be removed from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed927725-ef9f-4cd7-b349-0ccb0a6292e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the highly correlated variables\n",
    "z_score_df.drop(['No_Condition','65to74','Men',], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a54f7-87cd-4399-ba10-1d36cedf0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-plot the z-value correlations to check for highly correlated variables\n",
    "\n",
    "corr_2 = z_score_df.corr()\n",
    "threshold = 0.75\n",
    "highly_correlated_2 = (corr_2.abs() > threshold) & (corr_2.abs() < 1.0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(highly_correlated_2, cmap='coolwarm', cbar=False, annot=True)\n",
    "\n",
    "plt.title('New Highly Correlated Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b2fffb-3d43-474c-a9b9-cceb4a824569",
   "metadata": {},
   "source": [
    "Next, the data is tested for any NaN Values. These are dealst with using a method called Imputation. This replaces the NaN value with an estimate from the data. In this case the meidan of the rest of the data is used to impute as generally the distribution of the data is skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d8abd-522b-4225-b918-1d9be6b0ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "contains_nan = z_score_df.isna().any().any()\n",
    "\n",
    "if contains_nan:\n",
    "    print(\"The DataFrame contains NaN values.\")\n",
    "else:\n",
    "    print(\"The dataFrame does not contain NaN values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad83920-a771-488c-b519-f73b971ad16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_df.fillna(z_score_df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac59ea-b4f5-480a-9400-29b7828f21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41016b58-dfa6-4440-bc3d-c68489127c9f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For more easy manipulation we define short column names\n",
    "short_column_names = {\n",
    "    '30 to 44_percentage': '30to44',\n",
    "    '0 to 5_percentage': '0to5',\n",
    "    '75 to 84_percentage': '75to84',\n",
    "    'Females_percentage': 'Females',\n",
    "    #'Males_percentage': 'Males',\n",
    "    'Good health_percentage': 'Good_Health',\n",
    "    'Bad health_percentage': 'Bad_Health',\n",
    "    'Physical disability_percentage': 'Phyical_dis',\n",
    "    'Mental health condition_percentage': 'Mental_health',\n",
    "    'Provides no unpaid care_percentage': 'No_unpaid_care',\n",
    "    'Provides 50 or more hours unpaid care a week_percentage': 'Unpaid_care',\n",
    "    'Economically inactive: Student_percentage': 'Student',\n",
    "    #'Economically active: Unemployed_percentage': 'Unemployed',\n",
    "    'Economically active: Employee: Part-time_percentage': 'Part_time_empl',\n",
    "    'Economically active: Employee: Full-time_percentage': 'Full_time_empl',\n",
    "    'No adults in employment in household: With dependent children_percentage': 'Unempl+child',\n",
    "#    'Dependent children in household: All ages_percentage': 'Dep_Children',\n",
    "#    'Does not speak English well_percentage': 'Bad_English',\n",
    "#    'Speaks English well_percentage': 'Good_English',\n",
    "    'DE Semi-skilled and unskilled manual workers; on state benefit, unemployed, lowest grade workers_percentage': 'Unskilled',\n",
    "    'AB Higher and intermediate managerial/administrative/professional_percentage': 'Managerial',\n",
    "}\n",
    "\n",
    "z_score_df = z_score_df.rename(columns=short_column_names)\n",
    "edinburgh_census_data = edinburgh_census_data.rename(columns=short_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc65a1ec-d2d8-4828-b664-cedb5a410c89",
   "metadata": {},
   "source": [
    "### K-Means Clustering\n",
    "\n",
    "the K-Means clustring method involves a predetermined number of clusters and works by minimizing the distances between data points and their respective cluster centers\n",
    "\n",
    "It does this by creating a predefined number of seed and scattering them randomly. Each datapoint is then attached to its cloces seed. A new seed is then created at the centroid of each cluster. This is repeated untill the distance between every datapoint and the centroids can no longer be reduced.\n",
    "\n",
    "The first step in this process is determining the optimum number of centroids and clusters. The clusters must be as homogenous as possible, distict from each other and have similar numbers of datapoints in each cluster.\n",
    "\n",
    "To do this, we can examine the distribution of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94edc385-22bc-4844-8c15-60d039040598",
   "metadata": {},
   "source": [
    "#### Elbow method\n",
    "\n",
    "We can determine the optimum number of clusters by plotting the squared differences between the each observation and its cluster center. The larger the sum the more spread out the cluster and the more dissimilar it is from the rest of the cluster.\n",
    "\n",
    "Plotting the squared differences against the number of clusters and look for a sharp change in the plot. This is known as the elbow plot.\n",
    "\n",
    "The code below plots calculates the sum of squared distances for each number of clusters and plots them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10f0d74-e9c8-4e80-800d-cb4961025f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "\n",
    "\n",
    "Sum_of_squared_distances = []\n",
    "\n",
    "K_range = range(1,15)\n",
    "\n",
    "for k in K_range:\n",
    " km = KMeans(n_clusters=k)\n",
    " km = km.fit(z_score_df)\n",
    " Sum_of_squared_distances.append(km.inertia_)\n",
    "    \n",
    "plt.plot(K_range, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6c5203-c8ec-4597-8ae8-d289c4c632a3",
   "metadata": {},
   "source": [
    "Plotting the squred distances from the clusters shows the 'elbow' to be at around 6. We will therefore cluster the data into **6 groups** using K Means. \n",
    "\n",
    "In this next step, the distribution of datapoints in each cluster is plotted using a histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db26c5e2-35c9-43d9-a1e3-cf60cb3cc59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# KMeans with 6 clusters\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "kmeans.fit(z_score_df)\n",
    "labels = kmeans.predict(z_score_df)\n",
    "cluster_centres = kmeans.cluster_centers_\n",
    "z_score_df['Cluster'] = kmeans.labels_\n",
    "\n",
    "plt.hist(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82412f6-53a9-4a08-bd01-13e92c123617",
   "metadata": {},
   "source": [
    "The Histogram shows that there is a farily even distribution of datapoints across the 6 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f326c228-2c89-41ef-b86e-b1ba7642f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans with 6 clusters, after the validation with the Elbow method and histogram\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "kmeans.fit(z_score_df)\n",
    "labels = kmeans.predict(z_score_df)\n",
    "cluster_centres = kmeans.cluster_centers_\n",
    "\n",
    "#Create a new collumn which defines the cluster of each output area,\n",
    "z_score_df['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785439f3-dbbd-4790-9209-ecaa31612f6b",
   "metadata": {},
   "source": [
    "### Visualising the clusters\n",
    "\n",
    "In this next section, the datapoint in each cluster is plotted  in order to visualise how they are distributed as well as to see how datapoints from seperate clusters overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb32478-6860-4782-bc12-a4d577eea6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "clusters = kmeans.fit_predict(z_score_df)\n",
    "\n",
    "z_score_df['Cluster'] = clusters\n",
    "\n",
    "scaler = StandardScaler()\n",
    "stand_data_scaled = scaler.fit_transform(z_score_df)\n",
    "\n",
    "# PCA analysys.\n",
    "pca = PCA(n_components=2).fit(stand_data_scaled)\n",
    "pca_result = pca.transform(stand_data_scaled)\n",
    "\n",
    "#Percentage of variance explained by each of the selected components.\n",
    "variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Create a scatter plot\n",
    "fig = px.scatter(x=pca_result[:, 0], y=pca_result[:, 1], color=clusters,\n",
    "                 labels={'color': 'Cluster'},\n",
    "                 #title='Cluster Plot against 1st 2 Principal Components',\n",
    "                 opacity=0.7,\n",
    "                 width=800, \n",
    "                 height=800)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.show()\n",
    "\n",
    "print(f\"These two components explain {(variance_ratio.sum()*100):.2f}% of the point variability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe82f8-3912-4ce4-82a6-ed3fcb4baea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a static figure with the point variability included in the x/y-axis label.\n",
    "# So we can see what variability is provided by each component.\n",
    "\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "clusters = kmeans.fit_predict(z_score_df)\n",
    "\n",
    "z_score_df['Cluster'] = clusters\n",
    "\n",
    "# Standardize the data for PCA\n",
    "scaler = StandardScaler()\n",
    "stand_data_scaled = scaler.fit_transform(z_score_df)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2).fit(stand_data_scaled)\n",
    "pca_result = pca.transform(stand_data_scaled)\n",
    "\n",
    "#Percentage of variance explained by each of the selected components.\n",
    "variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=pca_result[:, 0], y=pca_result[:, 1], hue=clusters, palette='viridis', s=50, alpha=0.7)\n",
    "plt.title('Cluster Plot against 1st 2 Principal Components')\n",
    "plt.xlabel(f'Principal Component 1 variation: {variance_ratio[0]*100:.2f}%')\n",
    "plt.ylabel(f'Principal Component 2 variation: {variance_ratio[1]*100:.2f}%')\n",
    "plt.legend(title='Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac571546-646e-4c26-ae57-7c944ee3ee41",
   "metadata": {},
   "source": [
    "The two scatterplots show that across the 6 clusters, there are a few overlaping clusters. This is because the variables that we have used only explain 42% of the patterns shown in the dataset as shown in the first plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27ef84d-85c2-49e5-b914-fe85d03bef48",
   "metadata": {},
   "source": [
    "#### Plotting the cluster centers as radial plots\n",
    "\n",
    "In order understand the cluster it is important to understand what the defining features of each cluster are. This next code bit of code creates a radar plot which shows how different features of each cluster are distributed away from 0. This shows which features contribute to each clusters profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9ec52-bcc9-4619-a9a9-acd57f753d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans clustering\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "clusters = kmeans.fit_predict(z_score_df)\n",
    "\n",
    "# Get the cluster centers\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "\n",
    "# Get the cluster centers\n",
    "cluster_centers = pd.DataFrame(kmeans.cluster_centers_, columns=z_score_df.columns)\n",
    "\n",
    "# Create a new DataFrame with cluster assignments and column names\n",
    "#result_df = pd.DataFrame({'Cluster': clusters, 'Column': z_score_df.columns})\n",
    "\n",
    "cluster_centers.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393cf867-fb04-4d2f-ab86-0183976a138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Plotting cluster group 1\n",
    "#Define the row being analysed\n",
    "first_row_centers = cluster_centers.iloc[0, :-1]\n",
    "\n",
    "# len of features\n",
    "num_features = len(first_row_centers)\n",
    "\n",
    "# polar coordinates\n",
    "theta = np.linspace(0, 2 * np.pi, num_features, endpoint=True)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "ax.plot(theta, first_row_centers, linewidth=1, color='blue', marker='o', label='Centers')\n",
    "# Add an extra red line at the 0.0.\n",
    "ax.plot(theta, np.zeros_like(first_row_centers), color='red', linestyle='--', label='Avarage')\n",
    "\n",
    "ax.set_xticks(theta)\n",
    "ax.set_xticklabels(cluster_centers.columns[:-1], rotation=45, ha='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2f110-b183-4b2e-870e-4087d5dce7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting cluster group 2\n",
    "#Define the row being analysed\n",
    "second_row_centers = cluster_centers.iloc[1, :-1]\n",
    "\n",
    "# len of features\n",
    "num_features = len(second_row_centers)\n",
    "\n",
    "# polar coordinates\n",
    "theta = np.linspace(0, 2 * np.pi, num_features, endpoint=True)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "ax.plot(theta, second_row_centers, linewidth=1, color='blue', marker='o', label='Centers')\n",
    "# Add an extra red line at the 0.0 value showing the mean\n",
    "ax.plot(theta, np.zeros_like(second_row_centers), color='red', linestyle='--', label='Avarage')\n",
    "\n",
    "ax.set_xticks(theta)\n",
    "ax.set_xticklabels(cluster_centers.columns[:-1], rotation=45, ha='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b919b05-2998-4831-b514-3e06135ea1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting cluster group 3\n",
    "#Define the row being analysed\n",
    "third_row_centers = cluster_centers.iloc[2, :-1]\n",
    "\n",
    "# len of features\n",
    "num_features = len(third_row_centers)\n",
    "\n",
    "# polar coordinates\n",
    "theta = np.linspace(0, 2 * np.pi, num_features, endpoint=True)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "ax.plot(theta, third_row_centers, linewidth=1, color='blue', marker='o', label='Centers')\n",
    "# Add an extra red line at the 0.0 value showing the mean\n",
    "ax.plot(theta, np.zeros_like(third_row_centers), color='red', linestyle='--', label='Avarage')\n",
    "\n",
    "ax.set_xticks(theta)\n",
    "ax.set_xticklabels(cluster_centers.columns[:-1], rotation=45, ha='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd0365-eaa9-4754-8fef-cb3144c66d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting cluster group 4\n",
    "#Define the row being analysed\n",
    "fourth_row_centers = cluster_centers.iloc[3, :-1]\n",
    "\n",
    "# len of features\n",
    "num_features = len(fourth_row_centers)\n",
    "\n",
    "# polar coordinates\n",
    "theta = np.linspace(0, 2 * np.pi, num_features, endpoint=True)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "ax.plot(theta, fourth_row_centers, linewidth=1, color='blue', marker='o', label='Centers')\n",
    "# Add an extra red line at the 0.0 value showing the mean\n",
    "ax.plot(theta, np.zeros_like(fourth_row_centers), color='red', linestyle='--', label='Avarage')\n",
    "\n",
    "ax.set_xticks(theta)\n",
    "ax.set_xticklabels(cluster_centers.columns[:-1], rotation=45, ha='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ed577d-dc4b-406f-9dfb-0caf7de7b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting cluster group 5\n",
    "#Define the row being analysed\n",
    "fifth_row_centers = cluster_centers.iloc[4, :-1]\n",
    "\n",
    "# len of features\n",
    "num_features = len(fifth_row_centers)\n",
    "\n",
    "# polar coordinates\n",
    "theta = np.linspace(0, 2 * np.pi, num_features, endpoint=True)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "ax.plot(theta, fifth_row_centers, linewidth=1, color='blue', marker='o', label='Centers')\n",
    "# Add an extra red line at the 0.0 value showing the mean\n",
    "ax.plot(theta, np.zeros_like(fifth_row_centers), color='red', linestyle='--', label='Avarage')\n",
    "\n",
    "ax.set_xticks(theta)\n",
    "ax.set_xticklabels(cluster_centers.columns[:-1], rotation=45, ha='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc9efd5-fcd1-474d-bdb9-84c2dd934a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting cluster group 6\n",
    "#Define the row being analysed\n",
    "sixth_row_centers = cluster_centers.iloc[5, :-1]\n",
    "\n",
    "# len of features\n",
    "num_features = len(sixth_row_centers)\n",
    "\n",
    "# polar coordinates\n",
    "theta = np.linspace(0, 2 * np.pi, num_features, endpoint=True)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "ax.plot(theta, sixth_row_centers, linewidth=1, color='blue', marker='o', label='Centers')\n",
    "# Add an extra red line at the 0.0 value showing the mean\n",
    "ax.plot(theta, np.zeros_like(sixth_row_centers), color='red', linestyle='--', label='Avarage')\n",
    "\n",
    "ax.set_xticks(theta)\n",
    "ax.set_xticklabels(cluster_centers.columns[:-1], rotation=45, ha='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52cee5e-f340-4c45-8ae3-3af965b8f341",
   "metadata": {},
   "source": [
    "### Area Classifications\n",
    "\n",
    "Having analysed the attributes of each clusters, the named clusters below reflect the key attributes of each cluster.\n",
    "\n",
    "**Cluster 1: The Student Hub**\n",
    "* >Students\n",
    "* >Rented housing\n",
    "* >Providing no Unpaid Care\n",
    "\n",
    "**Cluster 2: The Family Professionals**\n",
    "* >Professionals\n",
    "* >Dependent Children\n",
    "* >Retired\n",
    "\n",
    "**Cluster 3: The Working Renters**\n",
    "* >Middle Aged\n",
    "* >Rented Housing\n",
    "* >Employed\n",
    "* >Providing no Unpaid Care\n",
    "* >Healthy\n",
    "\n",
    "**Cluster 4: The Care Community**\n",
    "* >Unskilled\n",
    "* >Unhealthy\n",
    "* >Council Housed\n",
    "* >Mental and physical disabilities \n",
    "* >Providing unpaid care\n",
    "\n",
    "**Cluster 5: The Healthy Professionals**\n",
    "* >Employed\n",
    "* >Professionals\n",
    "* >Middle aged\n",
    "* >With children\n",
    "* >Healthy\n",
    "\n",
    "**Cluster 6: The Secure Retirees**\n",
    "* >Retired\n",
    "* >Physically disabled\n",
    "* >Owned house\n",
    "* >Skilled\n",
    "* >Women\n",
    "* >Dependent Children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28a097e-370f-4295-8c2c-c75b104c322b",
   "metadata": {},
   "source": [
    "### Mapping the clusters \n",
    "The following code links the z_score data and the edinburgh output areas. It also names the clusters in order that they can be better visualised.\n",
    "\n",
    "It then visualises and maps the clusters across edinburgh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb4772-9981-4d76-bc12-5bc4df16419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all the variables apart from the cluster and ID data to avoid duplicating data\n",
    "z_score_df.drop([\n",
    "'0to5',\n",
    "'30to44',\n",
    "'Dep_child',\n",
    "'Women',\n",
    "'Employed',\n",
    "'Unemployed',\n",
    "'Student',\n",
    "'Retired',\n",
    "'Phys_Disability',\n",
    "'Ment_Condition',\n",
    "'No_unpaid_care',\n",
    "'Unpaid_care',\n",
    "'Professional',\n",
    "'Skilled',\n",
    "'Unskilled',\n",
    "'Healthy',\n",
    "'Unhealthy',\n",
    "'House_owned',\n",
    "'Council_house',\n",
    "'House_rented'], axis=1, inplace=True)\n",
    "z_score_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daccfc3d-57eb-4b76-9e58-3d66c0a3297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link the census data and the z_score data frame\n",
    "final_df = pd.concat([edinburgh_census_data, z_score_df], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea48de0-3e4b-4373-b3a7-69755b75c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the clusters using their apropriate names \n",
    "def rename_column(x):\n",
    "    # Map of integers to cluster names\n",
    "    cluster_names = {\n",
    "        0: \"The Student Hub\",\n",
    "        1: \"The Family Professionals\",\n",
    "        2: \"The Working Renters\",\n",
    "        3: \"The Care Community\",\n",
    "        4: \"The Healthy Professionals\",\n",
    "        5: \"The Secure Retirees\"\n",
    "    }\n",
    "    # Return the cluster name using the integer \n",
    "    return cluster_names.get(x, x)\n",
    "\n",
    "# Apply the function\n",
    "final_df['Cluster'] = final_df['Cluster'].apply(rename_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a60c0e-62ae-4ada-b1a4-825c79769b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an interactive map of the clusters across the edinburgh output areas\n",
    "final_df.explore(column='Cluster', cmap='Set3', tiles='CartoDB positron')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
